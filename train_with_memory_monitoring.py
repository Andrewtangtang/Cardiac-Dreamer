#!/usr/bin/env python3
"""
å¸¶è¨˜æ†¶é«”ç›£æ§çš„å®‰å…¨è¨“ç·´è…³æœ¬
æ•´åˆè¨˜æ†¶é«”æ´©æ¼æª¢æ¸¬ï¼Œé˜²æ­¢ç³»çµ±crash
"""

import os
import sys
import argparse
import torch
import pytorch_lightning as pl
from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor
import gc
import time

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

# å°å…¥è¨˜æ†¶é«”æª¢æ¸¬å™¨
from memory_leak_detector import MemoryLeakDetector, start_memory_monitoring, stop_memory_monitoring, check_memory, cleanup_memory

# å°å…¥è¨“ç·´æ¨¡çµ„
from src.train import main as original_main, load_config


class MemoryAwareCallback(pl.Callback):
    """è¨˜æ†¶é«”æ„ŸçŸ¥çš„å›èª¿å‡½æ•¸"""
    
    def __init__(self, memory_detector: MemoryLeakDetector):
        super().__init__()
        self.memory_detector = memory_detector
        self.last_cleanup_epoch = 0
        self.cleanup_interval = 5  # æ¯5å€‹epochæ¸…ç†ä¸€æ¬¡
        
    def on_train_epoch_start(self, trainer, pl_module):
        """è¨“ç·´epoché–‹å§‹æ™‚æª¢æŸ¥è¨˜æ†¶é«”"""
        current_epoch = trainer.current_epoch
        self.memory_detector.manual_check(epoch=current_epoch, step=None)
        
        # å®šæœŸæ¸…ç†è¨˜æ†¶é«”
        if current_epoch - self.last_cleanup_epoch >= self.cleanup_interval:
            print(f"ğŸ§¹ Epoch {current_epoch}: åŸ·è¡Œå®šæœŸè¨˜æ†¶é«”æ¸…ç†")
            self.memory_detector.force_cleanup()
            self.last_cleanup_epoch = current_epoch
    
    def on_train_epoch_end(self, trainer, pl_module):
        """è¨“ç·´epochçµæŸæ™‚æª¢æŸ¥è¨˜æ†¶é«”"""
        current_epoch = trainer.current_epoch
        self.memory_detector.manual_check(epoch=current_epoch, step=None)
        
        # æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
        summary = self.memory_detector.get_summary()
        if "cpu_memory_growth_mb" in summary:
            cpu_growth = summary["cpu_memory_growth_mb"]
            if cpu_growth > 2000:  # è¶…é2GBå¢é•·
                print(f"âš ï¸ CPUè¨˜æ†¶é«”å¢é•·éå¤š: {cpu_growth:.1f} MBï¼ŒåŸ·è¡Œå¼·åˆ¶æ¸…ç†")
                self.memory_detector.force_cleanup()
        
        if "gpu_memory_growth_mb" in summary:
            gpu_growth = summary["gpu_memory_growth_mb"]
            if gpu_growth > 1000:  # è¶…é1GBå¢é•·
                print(f"âš ï¸ GPUè¨˜æ†¶é«”å¢é•·éå¤š: {gpu_growth:.1f} MBï¼ŒåŸ·è¡Œå¼·åˆ¶æ¸…ç†")
                self.memory_detector.force_cleanup()
    
    def on_validation_epoch_end(self, trainer, pl_module):
        """é©—è­‰epochçµæŸæ™‚æ¸…ç†è¨˜æ†¶é«”"""
        # é©—è­‰å¾Œæ¸…ç†è¨˜æ†¶é«”ï¼Œå› ç‚ºé©—è­‰æœƒç´¯ç©å¤§é‡è¼¸å‡º
        if hasattr(pl_module, 'validation_step_outputs'):
            if len(pl_module.validation_step_outputs) > 0:
                print(f"ğŸ§¹ æ¸…ç†é©—è­‰è¼¸å‡º: {len(pl_module.validation_step_outputs)} å€‹æ¨£æœ¬")
                pl_module.validation_step_outputs.clear()
        
        # å¼·åˆ¶æ¸…ç†GPUç·©å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        gc.collect()


def setup_memory_safe_training(config_path: str, data_dir: str, output_dir: str):
    """è¨­ç½®è¨˜æ†¶é«”å®‰å…¨çš„è¨“ç·´ç’°å¢ƒ"""
    
    print("ğŸ”§ è¨­ç½®è¨˜æ†¶é«”å®‰å…¨è¨“ç·´ç’°å¢ƒ...")
    
    # 1. å•Ÿå‹•è¨˜æ†¶é«”ç›£æ§
    memory_detector = MemoryLeakDetector(
        check_interval=30.0,  # æ¯30ç§’æª¢æŸ¥ä¸€æ¬¡
        warning_threshold_mb=500,  # 500MBè­¦å‘Š
        critical_threshold_mb=1000  # 1GBå±éšª
    )
    memory_detector.start_monitoring()
    
    # 2. è¨­ç½®PyTorchè¨˜æ†¶é«”ç®¡ç†
    if torch.cuda.is_available():
        # è¨­ç½®GPUè¨˜æ†¶é«”åˆ†é…ç­–ç•¥
        torch.cuda.empty_cache()
        # è¨­ç½®è¨˜æ†¶é«”åˆ†ç‰‡ä»¥æ¸›å°‘ç¢ç‰‡åŒ–
        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
        print("âœ… GPUè¨˜æ†¶é«”ç®¡ç†å·²å„ªåŒ–")
    
    # 3. è¨­ç½®åƒåœ¾å›æ”¶
    gc.set_threshold(700, 10, 10)  # æ›´ç©æ¥µçš„åƒåœ¾å›æ”¶
    print("âœ… åƒåœ¾å›æ”¶å·²å„ªåŒ–")
    
    # 4. è¨­ç½®ç’°å¢ƒè®Šé‡
    os.environ['PYTHONHASHSEED'] = '42'
    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
    
    return memory_detector


def safe_train_main():
    """å®‰å…¨è¨“ç·´ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="å¸¶è¨˜æ†¶é«”ç›£æ§çš„å®‰å…¨è¨“ç·´")
    parser.add_argument("--config", type=str, default="configs/safe_training.yaml",
                       help="é…ç½®æ–‡ä»¶è·¯å¾‘")
    parser.add_argument("--data_dir", type=str, default="data/processed",
                       help="æ•¸æ“šç›®éŒ„")
    parser.add_argument("--output_dir", type=str, default="outputs_safe_training",
                       help="è¼¸å‡ºç›®éŒ„")
    parser.add_argument("--max_epochs", type=int, default=None,
                       help="æœ€å¤§è¨“ç·´è¼ªæ•¸ï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶ï¼‰")
    parser.add_argument("--batch_size", type=int, default=None,
                       help="æ‰¹æ¬¡å¤§å°ï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶ï¼‰")
    parser.add_argument("--enable_monitoring", action="store_true", default=True,
                       help="å•Ÿç”¨è¨˜æ†¶é«”ç›£æ§")
    
    args = parser.parse_args()
    
    print("ğŸš€ å•Ÿå‹•å¸¶è¨˜æ†¶é«”ç›£æ§çš„å®‰å…¨è¨“ç·´")
    print(f"   é…ç½®æ–‡ä»¶: {args.config}")
    print(f"   æ•¸æ“šç›®éŒ„: {args.data_dir}")
    print(f"   è¼¸å‡ºç›®éŒ„: {args.output_dir}")
    
    memory_detector = None
    
    try:
        # è¨­ç½®è¨˜æ†¶é«”å®‰å…¨ç’°å¢ƒ
        if args.enable_monitoring:
            memory_detector = setup_memory_safe_training(
                args.config, args.data_dir, args.output_dir
            )
        
        # è¼‰å…¥é…ç½®ä¸¦é€²è¡Œå®‰å…¨èª¿æ•´
        config_override = load_config(args.config) if args.config else {}
        
        # å®‰å…¨é…ç½®èª¿æ•´
        if "training" not in config_override:
            config_override["training"] = {}
        
        # å¼·åˆ¶ä½¿ç”¨å®‰å…¨è¨­ç½®
        safe_training_config = {
            "batch_size": args.batch_size or 4,  # å°æ‰¹æ¬¡å¤§å°
            "num_workers": 2,  # é™åˆ¶workeræ•¸é‡
            "precision": 16,  # æ··åˆç²¾åº¦
            "gradient_clip_val": 0.5,  # æ¢¯åº¦è£å‰ª
            "accumulate_grad_batches": 4,  # æ¢¯åº¦ç´¯ç©
            "max_epochs": args.max_epochs or 20,  # é™åˆ¶epochæ•¸é‡
            "check_val_every_n_epoch": 2,  # æ¸›å°‘é©—è­‰é »ç‡
            "log_every_n_steps": 50  # æ¸›å°‘æ—¥èªŒé »ç‡
        }
        
        config_override["training"].update(safe_training_config)
        
        print("ğŸ”§ æ‡‰ç”¨å®‰å…¨è¨“ç·´é…ç½®:")
        for key, value in safe_training_config.items():
            print(f"   {key}: {value}")
        
        # å‰µå»ºè‡¨æ™‚é…ç½®æ–‡ä»¶
        import tempfile
        import yaml
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            yaml.dump(config_override, f)
            temp_config_path = f.name
        
        # ä¿®æ”¹åƒæ•¸ä»¥ä½¿ç”¨è‡¨æ™‚é…ç½®
        original_args = argparse.Namespace(
            config=temp_config_path,
            data_dir=args.data_dir,
            output_dir=args.output_dir,
            manual_splits=False,
            train_patients=None,
            val_patients=None,
            test_patients=None
        )
        
        # æ·»åŠ è¨˜æ†¶é«”ç›£æ§å›èª¿
        if memory_detector:
            # é€™è£¡éœ€è¦ä¿®æ”¹åŸå§‹è¨“ç·´å‡½æ•¸ä»¥æ”¯æŒè‡ªå®šç¾©å›èª¿
            # æš«æ™‚ä½¿ç”¨åŸå§‹è¨“ç·´å‡½æ•¸
            print("âš ï¸ æ³¨æ„ï¼šè¨˜æ†¶é«”ç›£æ§å›èª¿éœ€è¦ä¿®æ”¹åŸå§‹è¨“ç·´å‡½æ•¸æ‰èƒ½å®Œå…¨æ•´åˆ")
        
        # åŸ·è¡Œè¨“ç·´
        print("ğŸ¯ é–‹å§‹å®‰å…¨è¨“ç·´...")
        original_main(original_args)
        
        print("âœ… è¨“ç·´å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ è¨“ç·´è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ è¨“ç·´éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†è³‡æº
        if memory_detector:
            print("ğŸ§¹ åŸ·è¡Œæœ€çµ‚è¨˜æ†¶é«”æ¸…ç†...")
            memory_detector.force_cleanup()
            memory_detector.stop_monitoring()
            
            # ç”Ÿæˆè¨˜æ†¶é«”å ±å‘Š
            report_path = os.path.join(args.output_dir, "memory_usage_report.png")
            os.makedirs(args.output_dir, exist_ok=True)
            memory_detector.generate_report(report_path)
            
            # é¡¯ç¤ºè¨˜æ†¶é«”æ‘˜è¦
            summary = memory_detector.get_summary()
            print("\nğŸ“Š æœ€çµ‚è¨˜æ†¶é«”ä½¿ç”¨æ‘˜è¦:")
            for key, value in summary.items():
                if isinstance(value, float):
                    print(f"   {key}: {value:.1f}")
                else:
                    print(f"   {key}: {value}")
        
        # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
        try:
            if 'temp_config_path' in locals():
                os.unlink(temp_config_path)
        except:
            pass
        
        # æœ€çµ‚æ¸…ç†
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        print("ğŸ å®‰å…¨è¨“ç·´è…³æœ¬åŸ·è¡Œå®Œç•¢")


def quick_memory_test():
    """å¿«é€Ÿè¨˜æ†¶é«”æ¸¬è©¦"""
    print("ğŸ§ª åŸ·è¡Œå¿«é€Ÿè¨˜æ†¶é«”æ¸¬è©¦...")
    
    detector = MemoryLeakDetector(check_interval=5.0)
    detector.start_monitoring()
    
    try:
        # æ¨¡æ“¬è¨“ç·´éç¨‹
        for epoch in range(3):
            print(f"\n--- æ¨¡æ“¬ Epoch {epoch} ---")
            
            # æ¨¡æ“¬å‰µå»ºä¸€äº›tensor
            tensors = []
            for step in range(5):
                if torch.cuda.is_available():
                    tensor = torch.randn(100, 100).cuda()
                else:
                    tensor = torch.randn(100, 100)
                tensors.append(tensor)
                
                if step % 2 == 0:
                    detector.manual_check(epoch=epoch, step=step)
            
            # æ¨¡æ“¬è¨˜æ†¶é«”æ´©æ¼ï¼ˆä¸æ¸…ç†tensorï¼‰
            if epoch < 2:
                print(f"   ä¿ç•™ {len(tensors)} å€‹tensorsï¼ˆæ¨¡æ“¬è¨˜æ†¶é«”æ´©æ¼ï¼‰")
            else:
                print(f"   æ¸…ç† {len(tensors)} å€‹tensors")
                del tensors
                detector.force_cleanup()
            
            time.sleep(2)
    
    finally:
        detector.stop_monitoring()
        detector.generate_report("memory_test_report.png")
        
        summary = detector.get_summary()
        print("\nğŸ“Š æ¸¬è©¦è¨˜æ†¶é«”æ‘˜è¦:")
        for key, value in summary.items():
            if isinstance(value, float):
                print(f"   {key}: {value:.1f}")
            else:
                print(f"   {key}: {value}")


if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        quick_memory_test()
    else:
        safe_train_main() 