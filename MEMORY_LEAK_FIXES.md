# è¨˜æ†¶é«”æ´©æ¼ä¿®å¾©æŒ‡å—

## ğŸ” ç™¼ç¾çš„è¨˜æ†¶é«”æ´©æ¼å•é¡Œ

### 1. **validation_step_outputs å’Œ test_step_outputs ç´¯ç©**
**å•é¡Œ**: åœ¨ `system.py` ä¸­ï¼Œæ¯å€‹ validation/test step éƒ½æœƒå°‡ tensor æ·»åŠ åˆ°åˆ—è¡¨ä¸­ï¼Œä½†é€™äº› tensor æ²’æœ‰æ­£ç¢ºç§»åˆ° CPU ä¸¦ä¸”æœƒç„¡é™ç´¯ç©ã€‚

**åŸå§‹ä»£ç¢¼å•é¡Œ**:
```python
self.validation_step_outputs.append({
    "predicted_action_composed": predicted_composed_action.detach().cpu(),
    "target_action_composed_gt": at1_6dof_gt.detach().cpu()
})
```

**ä¿®å¾©æ–¹æ¡ˆ**:
```python
# ğŸ”§ é™åˆ¶ç´¯ç©æ•¸é‡ä¸¦ç¢ºä¿tensorç§»åˆ°CPU
if len(self.validation_step_outputs) < self.max_validation_outputs:
    self.validation_step_outputs.append({
        "predicted_action_composed": predicted_composed_action.detach().cpu().clone(),
        "target_action_composed_gt": at1_6dof_gt.detach().cpu().clone()
    })
```

### 2. **DataLoader çš„ persistent_workers è¨˜æ†¶é«”æ´©æ¼**
**å•é¡Œ**: `persistent_workers=True` æœƒè®“ worker é€²ç¨‹æŒçºŒé‹è¡Œï¼Œç´¯ç©è¨˜æ†¶é«”è€Œä¸é‡‹æ”¾ã€‚

**åŸå§‹ä»£ç¢¼å•é¡Œ**:
```python
persistent_workers=True if train_config["num_workers"] > 0 else False
```

**ä¿®å¾©æ–¹æ¡ˆ**:
```python
persistent_workers=False,  # ğŸ”§ ç¦ç”¨persistent_workersé˜²æ­¢è¨˜æ†¶é«”ç´¯ç©
num_workers=min(train_config["num_workers"], 2),  # ğŸ”§ é™åˆ¶workeræ•¸é‡
```

### 3. **GPU è¨˜æ†¶é«”æ²’æœ‰å®šæœŸæ¸…ç†**
**å•é¡Œ**: GPU è¨˜æ†¶é«”ç¢ç‰‡åŒ–å’Œç·©å­˜ç´¯ç©å°è‡´ OOMã€‚

**ä¿®å¾©æ–¹æ¡ˆ**:
```python
# ğŸ”§ å®šæœŸæ¸…ç†GPUè¨˜æ†¶é«”
if batch_idx % 50 == 0:  # æ¯50å€‹batchæ¸…ç†ä¸€æ¬¡
    torch.cuda.empty_cache()
```

### 4. **æ¯å€‹ validation epoch éƒ½ç•«åœ–å°è‡´çš„æ€§èƒ½å•é¡Œ**
**å•é¡Œ**: åŸæœ¬æ¯å€‹ validation epoch éƒ½æœƒç”Ÿæˆ scatter plotsï¼Œé€™æœƒï¼š
- æ¶ˆè€—å¤§é‡ CPU å’Œè¨˜æ†¶é«”è³‡æº
- ç”¢ç”Ÿå¤§é‡æª”æ¡ˆï¼ˆæ¯å€‹epoch 7å€‹åœ–æª”ï¼‰
- å¯èƒ½å°è‡´ I/O ç“¶é ¸å’Œç³»çµ±ä¸ç©©å®š
- åœ¨é•·æ™‚é–“è¨“ç·´ä¸­ç´¯ç©å¤§é‡åœ–æª”

**åŸå§‹ä»£ç¢¼å•é¡Œ**:
```python
def on_validation_epoch_end(self):
    # æ¯å€‹epochéƒ½ç”Ÿæˆå®Œæ•´çš„scatter plots
    for i, dim_name in enumerate(dim_names):
        plt.figure(figsize=(8, 8))
        # ... ç•«åœ–é‚è¼¯ ...
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
```

**ä¿®å¾©æ–¹æ¡ˆ**:
```python
def on_validation_epoch_end(self):
    # ğŸ”§ å„ªåŒ–ï¼šåªæ”¶é›†æ•¸æ“šï¼Œä¸ç•«åœ–
    self.latest_validation_data = {
        "predictions": all_preds.clone(),
        "targets": all_targets.clone(),
        "epoch": current_epoch
    }
    print(f"ğŸ“Š Validation epoch {current_epoch}: æ”¶é›†äº† {len(all_preds)} å€‹æ¨£æœ¬çš„é æ¸¬æ•¸æ“š")
    print(f"   å°‡åœ¨è¨“ç·´çµæŸå¾Œç”Ÿæˆscatter plots")

def generate_final_validation_plots(self, output_dir: str = None):
    # ğŸ”§ åªåœ¨è¨“ç·´çµæŸå¾Œç”Ÿæˆä¸€æ¬¡æœ€çµ‚åœ–è¡¨
    # åŸºæ–¼æœ€å¾Œä¸€å€‹epochçš„é©—è­‰æ•¸æ“š
```

### 5. **epoch çµæŸæ™‚æ²’æœ‰å¼·åˆ¶åƒåœ¾å›æ”¶**
**å•é¡Œ**: Python åƒåœ¾å›æ”¶ä¸å¤ ç©æ¥µï¼Œå¤§å‹å°è±¡æ²’æœ‰åŠæ™‚é‡‹æ”¾ã€‚

**ä¿®å¾©æ–¹æ¡ˆ**:
```python
# ğŸ”§ ä¿®å¾©è¨˜æ†¶é«”æ´©æ¼ï¼šæ¸…ç†è¼¸å‡ºä¸¦å¼·åˆ¶åƒåœ¾å›æ”¶
self.validation_step_outputs.clear()
del all_preds, all_targets, preds_np, targets_np
gc.collect()
torch.cuda.empty_cache()
```

## ğŸ› ï¸ ä¿®å¾©çš„æ–‡ä»¶

### 1. `src/models/system.py`
- âœ… æ·»åŠ è¨˜æ†¶é«”ç®¡ç†åƒæ•¸ (`max_validation_outputs`, `max_test_outputs`)
- âœ… ä¿®å¾© validation_step å’Œ test_step ä¸­çš„ tensor æ´©æ¼
- âœ… æ·»åŠ å®šæœŸ GPU è¨˜æ†¶é«”æ¸…ç†
- âœ… å¼·åŒ– epoch çµæŸæ™‚çš„è¨˜æ†¶é«”æ¸…ç†
- âœ… æ·»åŠ åƒåœ¾å›æ”¶æ©Ÿåˆ¶
- âœ… **å„ªåŒ– validation åœ–è¡¨ç”Ÿæˆ**ï¼šå¾æ¯å€‹epochéƒ½ç•«åœ–æ”¹ç‚ºåªåœ¨è¨“ç·´çµæŸå¾Œç•«ä¸€æ¬¡

### 2. `src/train.py`
- âœ… ä¿®å¾© DataLoader é…ç½®
- âœ… ç¦ç”¨ persistent_workers
- âœ… é™åˆ¶ num_workers æ•¸é‡
- âœ… æ¢ä»¶æ€§ä½¿ç”¨ pin_memory
- âœ… **æ›´æ–°è¨“ç·´æµç¨‹**ï¼šåœ¨è¨“ç·´çµæŸå¾Œèª¿ç”¨æœ€çµ‚åœ–è¡¨ç”Ÿæˆ

### 3. æ–°å¢å·¥å…·

#### `memory_leak_detector.py`
- ğŸ” å¯¦æ™‚è¨˜æ†¶é«”ç›£æ§
- âš ï¸ è‡ªå‹•è­¦å‘Šå’Œå»ºè­°
- ğŸ“Š è¨˜æ†¶é«”ä½¿ç”¨å ±å‘Šç”Ÿæˆ
- ğŸ§¹ å¼·åˆ¶è¨˜æ†¶é«”æ¸…ç†åŠŸèƒ½

#### `train_with_memory_monitoring.py`
- ğŸš€ æ•´åˆè¨˜æ†¶é«”ç›£æ§çš„å®‰å…¨è¨“ç·´
- ğŸ”§ è‡ªå‹•æ‡‰ç”¨å®‰å…¨é…ç½®
- ğŸ“ˆ è¨“ç·´éç¨‹è¨˜æ†¶é«”è¿½è¹¤

## ğŸ¯ ä½¿ç”¨æ–¹æ³•

### 1. ä½¿ç”¨ä¿®å¾©å¾Œçš„æ­£å¸¸è¨“ç·´
```bash
# ä½¿ç”¨ä¿®å¾©å¾Œçš„ç³»çµ±é€²è¡Œè¨“ç·´
pipenv run python src/train.py --config configs/safe_training.yaml --data_dir data/processed --output_dir outputs_safe
```

### 2. ä½¿ç”¨è¨˜æ†¶é«”ç›£æ§è¨“ç·´
```bash
# å¸¶è¨˜æ†¶é«”ç›£æ§çš„å®‰å…¨è¨“ç·´
python train_with_memory_monitoring.py --config configs/safe_training.yaml --data_dir data/processed --output_dir outputs_monitored
```

### 3. æ¸¬è©¦è¨˜æ†¶é«”æª¢æ¸¬å™¨
```bash
# æ¸¬è©¦è¨˜æ†¶é«”æ´©æ¼æª¢æ¸¬å™¨
python memory_leak_detector.py
python train_with_memory_monitoring.py test
```

## ğŸ“Š æ•ˆæœå°æ¯”

### ä¿®å¾©å‰çš„å•é¡Œ
- âŒ è¨˜æ†¶é«”æŒçºŒå¢é•·ï¼Œæœ€çµ‚å°è‡´ OOM æˆ–ç³»çµ± crash
- âŒ validation_step_outputs ç„¡é™ç´¯ç©
- âŒ GPU è¨˜æ†¶é«”ç¢ç‰‡åŒ–åš´é‡
- âŒ DataLoader worker é€²ç¨‹è¨˜æ†¶é«”æ´©æ¼
- âŒ **æ¯å€‹ validation epoch éƒ½ç•«åœ–**ï¼Œæ¶ˆè€—å¤§é‡è³‡æºå’Œç”¢ç”Ÿå¤§é‡æª”æ¡ˆ

### ä¿®å¾©å¾Œçš„æ”¹å–„
- âœ… è¨˜æ†¶é«”ä½¿ç”¨ç©©å®šï¼Œæœ‰ä¸Šé™æ§åˆ¶
- âœ… å®šæœŸè‡ªå‹•æ¸…ç†ï¼Œé˜²æ­¢ç´¯ç©
- âœ… GPU è¨˜æ†¶é«”æœ‰æ•ˆç®¡ç†
- âœ… å¯ä»¥é•·æ™‚é–“ç©©å®šè¨“ç·´
- âœ… **åªåœ¨è¨“ç·´çµæŸå¾Œç•«ä¸€æ¬¡åœ–**ï¼Œå¤§å¹…æ¸›å°‘ I/O å’Œè¨˜æ†¶é«”å£“åŠ›
- âœ… **é«˜æ•ˆçš„åœ–è¡¨ç”Ÿæˆ**ï¼Œé¿å…è¨“ç·´éç¨‹ä¸­çš„ I/O ç“¶é ¸

## ğŸ”§ å®‰å…¨é…ç½®å»ºè­°

### é‡å° GTX 1650 (4GB) çš„å®‰å…¨è¨­ç½®
```yaml
training:
  batch_size: 4                   # å°æ‰¹æ¬¡å¤§å°
  num_workers: 2                  # é™åˆ¶workeræ•¸é‡
  precision: 16                   # æ··åˆç²¾åº¦ç¯€çœè¨˜æ†¶é«”
  gradient_clip_val: 0.5          # æ¢¯åº¦è£å‰ª
  accumulate_grad_batches: 4      # æ¢¯åº¦ç´¯ç©æ¨¡æ“¬å¤§æ‰¹æ¬¡
  max_epochs: 50                  # é©ä¸­çš„epochæ•¸é‡
  check_val_every_n_epoch: 2      # æ¸›å°‘é©—è­‰é »ç‡
```

### æ¨¡å‹é…ç½®èª¿æ•´
```yaml
model:
  d_model: 512                    # å¾768é™åˆ°512
  num_heads: 8                    # å¾12é™åˆ°8  
  num_layers: 4                   # å¾6é™åˆ°4
  token_type: "patch"             # ä½¿ç”¨æ›´é«˜æ•ˆçš„patch tokens
```

## ğŸš¨ è­¦å‘Šä¿¡è™Ÿ

### CPU è¨˜æ†¶é«”æ´©æ¼ä¿¡è™Ÿ
- è¨˜æ†¶é«”ä½¿ç”¨é‡æŒçºŒå¢é•·è¶…é 2GB
- ç³»çµ±éŸ¿æ‡‰è®Šæ…¢
- å‡ºç¾ "Memory Error" æˆ– "Out of Memory"

### GPU è¨˜æ†¶é«”æ´©æ¼ä¿¡è™Ÿ
- CUDA OOM éŒ¯èª¤
- GPU è¨˜æ†¶é«”ä½¿ç”¨ç‡æ¥è¿‘ 100%
- è¨“ç·´é€Ÿåº¦çªç„¶ä¸‹é™

### ç³»çµ±ä¸ç©©å®šä¿¡è™Ÿ
- æ•´å°é›»è…¦ crash
- è—å±æˆ–é»‘å±
- é¢¨æ‰‡ç‹‚è½‰ï¼Œæº«åº¦éé«˜

## ğŸ’¡ é é˜²æªæ–½

### 1. è¨“ç·´å‰æª¢æŸ¥
```bash
# æª¢æŸ¥ç³»çµ±ç‹€æ…‹
python check_system.py

# æ¸¬è©¦è¨˜æ†¶é«”æª¢æ¸¬å™¨
python train_with_memory_monitoring.py test
```

### 2. è¨“ç·´ä¸­ç›£æ§
- ä½¿ç”¨ `monitor_training.py` å¯¦æ™‚ç›£æ§
- è§€å¯Ÿè¨˜æ†¶é«”ä½¿ç”¨è¶¨å‹¢
- æ³¨æ„æº«åº¦å’Œè² è¼‰

### 3. ç·Šæ€¥è™•ç†
```python
# åœ¨ Python ä¸­ç·Šæ€¥æ¸…ç†è¨˜æ†¶é«”
import gc
import torch

gc.collect()
if torch.cuda.is_available():
    torch.cuda.empty_cache()
```

## ğŸ‰ ç¸½çµ

é€šéé€™äº›ä¿®å¾©ï¼Œæˆ‘å€‘è§£æ±ºäº†ï¼š

1. **ä¸»è¦è¨˜æ†¶é«”æ´©æ¼æºé ­** - validation/test outputs ç´¯ç©
2. **DataLoader è¨˜æ†¶é«”å•é¡Œ** - persistent_workers å’Œéå¤š workers
3. **GPU è¨˜æ†¶é«”ç®¡ç†** - å®šæœŸæ¸…ç†å’Œç¢ç‰‡åŒ–è™•ç†
4. **ç›£æ§å’Œé è­¦æ©Ÿåˆ¶** - å¯¦æ™‚æª¢æ¸¬å’Œè‡ªå‹•å»ºè­°
5. **Validation åœ–è¡¨æ€§èƒ½å•é¡Œ** - å¾æ¯å€‹epochéƒ½ç•«åœ–æ”¹ç‚ºè¨“ç·´çµæŸå¾Œç•«ä¸€æ¬¡

ç¾åœ¨ç³»çµ±å¯ä»¥ï¼š
- âœ… é•·æ™‚é–“ç©©å®šè¨“ç·´è€Œä¸ crash
- âœ… è‡ªå‹•ç›£æ§å’Œè­¦å‘Šè¨˜æ†¶é«”å•é¡Œ
- âœ… åœ¨è³‡æºå—é™çš„ç¡¬é«”ä¸Šå®‰å…¨é‹è¡Œ
- âœ… æä¾›è©³ç´°çš„è¨˜æ†¶é«”ä½¿ç”¨å ±å‘Š
- âœ… **é«˜æ•ˆçš„åœ–è¡¨ç”Ÿæˆ**ï¼Œé¿å…è¨“ç·´éç¨‹ä¸­çš„ I/O ç“¶é ¸

**å»ºè­°ä½¿ç”¨ `configs/safe_training.yaml` é…ç½®å’Œ `train_with_memory_monitoring.py` è…³æœ¬é€²è¡Œå®‰å…¨è¨“ç·´ï¼**