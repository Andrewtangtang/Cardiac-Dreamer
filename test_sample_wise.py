#!/usr/bin/env python
"""
æ¸¬è©¦æŒ‰æ¨£æœ¬æ¯”ä¾‹åˆ†å‰²åŠŸèƒ½ (70%/15%/15%)
"""

import sys
import os
sys.path.insert(0, '.')

import torchvision.transforms as transforms

# Set up data transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

try:
    from src.train import SampleWiseCrossPatientDataset
    
    print("=== ğŸ” æ¸¬è©¦æŒ‰æ¨£æœ¬æ¯”ä¾‹åˆ†å‰²åŠŸèƒ½ ===")
    
    # å‰µå»ºæŒ‰æ¨£æœ¬æ¯”ä¾‹åˆ†å‰²çš„è³‡æ–™é›†
    print("\nå‰µå»ºè¨“ç·´è³‡æ–™é›†ï¼ˆæŒ‰æ¨£æœ¬æ¯”ä¾‹ 70%ï¼‰:")
    train_dataset = SampleWiseCrossPatientDataset(
        data_dir='data/processed',
        transform=transform,
        split="train",
        train_ratio=0.7,
        val_ratio=0.15,
        test_ratio=0.15
    )
    
    print("\nå‰µå»ºé©—è­‰è³‡æ–™é›†ï¼ˆæŒ‰æ¨£æœ¬æ¯”ä¾‹ 15%ï¼‰:")
    val_dataset = SampleWiseCrossPatientDataset(
        data_dir='data/processed',
        transform=transform,
        split="val",
        train_ratio=0.7,
        val_ratio=0.15,
        test_ratio=0.15
    )
    
    print("\nå‰µå»ºæ¸¬è©¦è³‡æ–™é›†ï¼ˆæŒ‰æ¨£æœ¬æ¯”ä¾‹ 15%ï¼‰:")
    test_dataset = SampleWiseCrossPatientDataset(
        data_dir='data/processed',
        transform=transform,
        split="test",
        train_ratio=0.7,
        val_ratio=0.15,
        test_ratio=0.15
    )
    
    total_samples = len(train_dataset) + len(val_dataset) + len(test_dataset)
    
    print(f"\n=== ğŸ“Š æ¨£æœ¬æ¯”ä¾‹çµæœ ===")
    print(f"ç¸½æ¨£æœ¬æ•¸: {total_samples}")
    print(f"è¨“ç·´é›†: {len(train_dataset)} æ¨£æœ¬ ({len(train_dataset)/total_samples:.1%})")
    print(f"é©—è­‰é›†: {len(val_dataset)} æ¨£æœ¬ ({len(val_dataset)/total_samples:.1%})") 
    print(f"æ¸¬è©¦é›†: {len(test_dataset)} æ¨£æœ¬ ({len(test_dataset)/total_samples:.1%})")
    
    print(f"\n=== ğŸ§¬ æ¯å€‹åˆ†å‰²ä¸­çš„ç—…æ‚£åˆ†ä½ˆ ===")
    print(f"è¨“ç·´é›†ç—…æ‚£: {train_dataset.get_patient_stats()}")
    print(f"é©—è­‰é›†ç—…æ‚£: {val_dataset.get_patient_stats()}")
    print(f"æ¸¬è©¦é›†ç—…æ‚£: {test_dataset.get_patient_stats()}")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™æ´©æ¼
    train_patients = set(train_dataset.get_patient_stats().keys())
    val_patients = set(val_dataset.get_patient_stats().keys())
    test_patients = set(test_dataset.get_patient_stats().keys())
    
    print(f"\n=== âš ï¸  è³‡æ–™æ´©æ¼æª¢æŸ¥ ===")
    train_val_overlap = train_patients & val_patients
    train_test_overlap = train_patients & test_patients
    val_test_overlap = val_patients & test_patients
    
    if train_val_overlap:
        print(f"âš ï¸  è¨“ç·´-é©—è­‰é‡ç–Šç—…æ‚£: {train_val_overlap}")
    if train_test_overlap:
        print(f"âš ï¸  è¨“ç·´-æ¸¬è©¦é‡ç–Šç—…æ‚£: {train_test_overlap}")
    if val_test_overlap:
        print(f"âš ï¸  é©—è­‰-æ¸¬è©¦é‡ç–Šç—…æ‚£: {val_test_overlap}")
    
    if not (train_val_overlap or train_test_overlap or val_test_overlap):
        print("âœ… æ²’æœ‰ç—…æ‚£é‡ç–Šï¼ˆä½†ä»å¯èƒ½æœ‰æ¨£æœ¬å±¤ç´šçš„æ´©æ¼ï¼‰")
    
    # æ¸¬è©¦åœ–ç‰‡è·¯å¾‘æ˜¯å¦æ­£ç¢º
    print(f"\n=== ğŸ“ åœ–ç‰‡è·¯å¾‘é©—è­‰ ===")
    try:
        sample_img, _, _, _ = train_dataset[0]
        print(f"âœ… æˆåŠŸè¼‰å…¥è¨“ç·´é›†ç¬¬ä¸€å¼µåœ–ç‰‡ï¼Œå°ºå¯¸: {sample_img.shape}")
        
        sample_img, _, _, _ = val_dataset[0] 
        print(f"âœ… æˆåŠŸè¼‰å…¥é©—è­‰é›†ç¬¬ä¸€å¼µåœ–ç‰‡ï¼Œå°ºå¯¸: {sample_img.shape}")
        
        sample_img, _, _, _ = test_dataset[0]
        print(f"âœ… æˆåŠŸè¼‰å…¥æ¸¬è©¦é›†ç¬¬ä¸€å¼µåœ–ç‰‡ï¼Œå°ºå¯¸: {sample_img.shape}")
        
    except Exception as e:
        print(f"âŒ åœ–ç‰‡è¼‰å…¥å¤±æ•—: {e}")
    
    print("\n=== âœ… æ¸¬è©¦å®Œæˆï¼ ===")
    print("âœ… æˆåŠŸå¯¦ç¾æŒ‰æ¨£æœ¬æ¯”ä¾‹ 70%/15%/15% åˆ†å‰²")
    print("âœ… æ‰€æœ‰ç—…æ‚£è³‡æ–™å¤¾éƒ½è¢«è‡ªå‹•åµæ¸¬å’Œè¼‰å…¥")
    print("âœ… åœ–ç‰‡è·¯å¾‘æ­£ç¢ºï¼Œå¯ä»¥æˆåŠŸè¼‰å…¥")
    print("âš ï¸  æ³¨æ„ï¼šé€™ç¨®åˆ†å‰²æ–¹å¼å¯èƒ½é€ æˆè³‡æ–™æ´©æ¼")
    
except Exception as e:
    print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
    import traceback
    traceback.print_exc() 